{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/tarizatique/web-scraping-and-sentiment-anaysis-imdb?scriptVersionId=106053539\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown","outputs":[],"execution_count":0},{"cell_type":"markdown","source":"Objectives of Project\n\n1. Reviews Preprocessing and Cleaning\n2. Story Generation and Visualization from reviews\n3. Extracting Features from Cleaned reviews\n4. Building Wordclouds\n5. Sentiment Analysis","metadata":{}},{"cell_type":"code","source":"\nimport pandas as pd\nimport requests\nimport pandas as pd\nfrom bs4 import BeautifulSoup\nimport nltk\nimport re\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nimport nltk\nnltk.download('omw-1.4')\nfrom nltk.util import ngrams\nfrom wordcloud import WordCloud, STOPWORDS\nnltk.download('punkt')\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#pasting links of the website we want to scrap\nurl = \"https://www.imdb.com/title/tt0111161/reviews?ref_=tt_urv\"\npage = requests.get(url)\npage\n","metadata":{"execution":{"iopub.status.busy":"2022-09-19T18:34:00.926871Z","iopub.execute_input":"2022-09-19T18:34:00.927285Z","iopub.status.idle":"2022-09-19T18:34:02.422703Z","shell.execute_reply.started":"2022-09-19T18:34:00.927251Z","shell.execute_reply":"2022-09-19T18:34:02.42162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#changing the raw format to  alignment\nsoup = BeautifulSoup(page.content,\"html.parser\")\nsoup.prettify()\nscrape_review = soup.find_all('div', class_=\"text show-more__control\")\n#running these may take too much space and it will waste enough time in scrolling\n","metadata":{"execution":{"iopub.status.busy":"2022-09-19T18:34:12.586235Z","iopub.execute_input":"2022-09-19T18:34:12.586643Z","iopub.status.idle":"2022-09-19T18:34:12.773991Z","shell.execute_reply.started":"2022-09-19T18:34:12.586612Z","shell.execute_reply":"2022-09-19T18:34:12.773082Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#creating an empty list naming movie and adding all review into them\n#sparse review\nmovies = []\nfor movie in scrape_review:\n    movie = movie.get_text().replace('\\n', \"\")\n    movie = movie.strip(\" \")\n    movies.append(movie)\n    movie = movie.strip(\" \")\n   ","metadata":{"execution":{"iopub.status.busy":"2022-09-19T18:11:03.482724Z","iopub.execute_input":"2022-09-19T18:11:03.483162Z","iopub.status.idle":"2022-09-19T18:11:03.490324Z","shell.execute_reply.started":"2022-09-19T18:11:03.483125Z","shell.execute_reply":"2022-09-19T18:11:03.488912Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#you can chekc all review here\nmovies","metadata":{"execution":{"iopub.status.busy":"2022-09-19T18:11:29.250266Z","iopub.execute_input":"2022-09-19T18:11:29.251248Z","iopub.status.idle":"2022-09-19T18:11:29.259981Z","shell.execute_reply.started":"2022-09-19T18:11:29.251207Z","shell.execute_reply":"2022-09-19T18:11:29.258831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Text Cleaning**","metadata":{}},{"cell_type":"code","source":"# writng reviews in a text file \nwith open(\"movies.txt\", \"w\", encoding='utf8') as output:\n    output.write(str(movies))\n    \n    # Joinining all the reviews into single paragraph \n    ip_rev_string = \" \".join(movies)","metadata":{"execution":{"iopub.status.busy":"2022-09-19T18:12:02.344673Z","iopub.execute_input":"2022-09-19T18:12:02.345134Z","iopub.status.idle":"2022-09-19T18:12:02.352318Z","shell.execute_reply.started":"2022-09-19T18:12:02.345081Z","shell.execute_reply":"2022-09-19T18:12:02.351095Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n\n# Removing unwanted symbols incase if exists\nip_rev_string = re.sub(\"[^A-Za-z\" \"]+\", \" \", ip_rev_string).lower()\n# ip_rev_string = re.sub(\"[0-9\" \"]+\",\" \", ip_rev_string)\n\n# words that contained in the reviews\nip_reviews_words = ip_rev_string.split(\" \")\n\nip_reviews_words = ip_reviews_words[1:]","metadata":{"execution":{"iopub.status.busy":"2022-09-19T18:12:06.702832Z","iopub.execute_input":"2022-09-19T18:12:06.703295Z","iopub.status.idle":"2022-09-19T18:12:06.714103Z","shell.execute_reply.started":"2022-09-19T18:12:06.703261Z","shell.execute_reply":"2022-09-19T18:12:06.71307Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#converting into sparse matrix\ncv = CountVectorizer()\nX =cv.fit_transform(ip_reviews_words)","metadata":{"execution":{"iopub.status.busy":"2022-09-19T18:12:45.372507Z","iopub.execute_input":"2022-09-19T18:12:45.372919Z","iopub.status.idle":"2022-09-19T18:12:45.417434Z","shell.execute_reply.started":"2022-09-19T18:12:45.372882Z","shell.execute_reply":"2022-09-19T18:12:45.41645Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#adding my stopwords custom gile you can either download it from nltk library\nwith open(\"../input/stopwords/stopwords.txt\", \"r\") as sw:\n    stop_words = sw.read()\n    \nstop_words = stop_words.split(\"\\n\")\n#adding some custom that are not present in stopwords file\nstop_words.extend([\"movie\",\"film\",\"shawshank\",\"time\",\"prison\",\"tim robbins\",\"morgan\",\"freeman\",\"stephen\",\"king\",\"tim\",\"robbins\",\"andy\",\"shawsank redemption\",\"redemption\",\"character\",\"movies\",\"tim robbins\",\"stephen king\",\"morgan freeman\",\"frank darabont\",\"andy dufresne\"])\n\nip_reviews_words = [w for w in ip_reviews_words if not w in stop_words]\n\n# Joinining all the reviews into single paragraph \nip_rev_string = \" \".join(ip_reviews_words)","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# WordCloud can be performed on the string inputs.\n# Corpus level word cloud\n\nwordcloud_ip = WordCloud(background_color='White',\n                      width=1800,\n                      height=1400\n                     ).generate(ip_rev_string)\nplt.imshow(wordcloud_ip)","metadata":{"execution":{"iopub.status.busy":"2022-09-19T18:20:38.260842Z","iopub.execute_input":"2022-09-19T18:20:38.261237Z","iopub.status.idle":"2022-09-19T18:20:43.873706Z","shell.execute_reply.started":"2022-09-19T18:20:38.261206Z","shell.execute_reply":"2022-09-19T18:20:43.872581Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# positive words # Choose the path for +ve words stored in system\nwith open(\"../input/positvie-words/positve words.txt\",\"r\") as pos:\n  poswords = pos.read().split(\"\\n\")\n\n# Positive word cloud\n# Choosing the only words which are present in positive words\nip_pos_in_pos = \" \".join ([w for w in ip_reviews_words if w in poswords])","metadata":{"execution":{"iopub.status.busy":"2022-09-19T18:21:14.167891Z","iopub.execute_input":"2022-09-19T18:21:14.168273Z","iopub.status.idle":"2022-09-19T18:21:14.280254Z","shell.execute_reply.started":"2022-09-19T18:21:14.168242Z","shell.execute_reply":"2022-09-19T18:21:14.279083Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wordcloud_pos_in_pos = WordCloud(\n                      background_color='White',\n                      width=1800,\n                      height=1400\n                     ).generate(ip_pos_in_pos)\nplt.figure(2)\nplt.imshow(wordcloud_pos_in_pos)","metadata":{"execution":{"iopub.status.busy":"2022-09-19T18:21:19.614636Z","iopub.execute_input":"2022-09-19T18:21:19.615061Z","iopub.status.idle":"2022-09-19T18:21:25.630963Z","shell.execute_reply.started":"2022-09-19T18:21:19.615025Z","shell.execute_reply":"2022-09-19T18:21:25.629908Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# negative words Choose path for -ve words stored in system\nwith open(\"../input/stopwords/Negative words.txt\", \"r\") as neg:\n  negwords = neg.read().split(\"\\n\")\n\n# negative word cloud\n# Choosing the only words which are present in negwords\nip_neg_in_neg = \" \".join ([w for w in ip_reviews_words if w in negwords])","metadata":{"execution":{"iopub.status.busy":"2022-09-19T18:21:39.478981Z","iopub.execute_input":"2022-09-19T18:21:39.479341Z","iopub.status.idle":"2022-09-19T18:21:39.730336Z","shell.execute_reply.started":"2022-09-19T18:21:39.479312Z","shell.execute_reply":"2022-09-19T18:21:39.72923Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#wordcloud with negative words\nwordcloud_neg_in_neg = WordCloud(\n                      background_color='black',\n                      width=1800,\n                      height=1400\n                     ).generate(ip_neg_in_neg)\nplt.figure(3)\nplt.imshow(wordcloud_neg_in_neg)","metadata":{"execution":{"iopub.status.busy":"2022-09-19T18:21:43.97576Z","iopub.execute_input":"2022-09-19T18:21:43.976145Z","iopub.status.idle":"2022-09-19T18:21:48.706255Z","shell.execute_reply.started":"2022-09-19T18:21:43.976114Z","shell.execute_reply":"2022-09-19T18:21:48.705189Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#lemmetization\nWNL = nltk.WordNetLemmatizer()","metadata":{"execution":{"iopub.status.busy":"2022-09-19T18:21:56.981734Z","iopub.execute_input":"2022-09-19T18:21:56.982128Z","iopub.status.idle":"2022-09-19T18:21:56.98703Z","shell.execute_reply.started":"2022-09-19T18:21:56.982098Z","shell.execute_reply":"2022-09-19T18:21:56.985831Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Lowercase and tokenize\ntext = ip_rev_string.lower()\n\n# Remove single quote early since it causes problems with the tokenizer.\ntext = text.replace(\"'\", \"\")\n\ntokens = nltk.word_tokenize(text)\ntext1 = nltk.Text(tokens)\n","metadata":{"execution":{"iopub.status.busy":"2022-09-19T18:22:01.000232Z","iopub.execute_input":"2022-09-19T18:22:01.000633Z","iopub.status.idle":"2022-09-19T18:22:01.030672Z","shell.execute_reply.started":"2022-09-19T18:22:01.000597Z","shell.execute_reply":"2022-09-19T18:22:01.029657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Remove extra chars and remove stop words.\ntext_content = [''.join(re.split(\"[ .,;:!?‘’``''@#$%^_&*()<>{}~\\n\\t\\\\\\-]\", word)) for word in text1]\n\n# Create a set of stopwords\nstopwords_wc = set(STOPWORDS)\ncustomised_words = [\"movie\",\"film\",\"shawshank\",\"time\",\"prison\",\"tim robbins\",\"morgan\",\"freeman\",\"stephen\",\"king\",\"tim\",\"robbins\",\"andy\",\"shawsank redemption\",\"redemption\",\"character\",\"movies\",\"tim robbins\",\"stephen king\",\"morgan freeman\",\"frank darabont\",\"andy dufresne\" ]\n# If you want to remove any particular word form text which does not contribute much in meaning\n\nnew_stopwords = stopwords_wc.union(customised_words)\n","metadata":{"execution":{"iopub.status.busy":"2022-09-19T18:23:25.640333Z","iopub.execute_input":"2022-09-19T18:23:25.640722Z","iopub.status.idle":"2022-09-19T18:23:25.654691Z","shell.execute_reply.started":"2022-09-19T18:23:25.640685Z","shell.execute_reply":"2022-09-19T18:23:25.653722Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Remove stop words\ntext_content = [word for word in text_content if word not in new_stopwords]\n\n# Take only non-empty entries\ntext_content = [s for s in text_content if len(s) != 0]\n\n# Best to get the lemmas of each word to reduce the number of similar words\ntext_content = [WNL.lemmatize(t) for t in text_content]\n ","metadata":{"execution":{"iopub.status.busy":"2022-09-19T18:24:47.238921Z","iopub.execute_input":"2022-09-19T18:24:47.239352Z","iopub.status.idle":"2022-09-19T18:24:49.238381Z","shell.execute_reply.started":"2022-09-19T18:24:47.239318Z","shell.execute_reply":"2022-09-19T18:24:49.237183Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#Unigram\nunigram = []\nn = 1\nunigrams = ngrams(text_content, n)\n  for item in unigrams:\n   \n   print(item)","metadata":{"execution":{"iopub.status.busy":"2022-09-19T18:26:09.92263Z","iopub.execute_input":"2022-09-19T18:26:09.923016Z","iopub.status.idle":"2022-09-19T18:26:09.95195Z","shell.execute_reply.started":"2022-09-19T18:26:09.922986Z","shell.execute_reply":"2022-09-19T18:26:09.950886Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Bigrams**","metadata":{}},{"cell_type":"code","source":"\nbigrams_list = list(nltk.bigrams(text_content))\n# we can show and print ot\nprint(bigrams_list)","metadata":{"execution":{"iopub.status.busy":"2022-09-19T18:27:03.787352Z","iopub.execute_input":"2022-09-19T18:27:03.787725Z","iopub.status.idle":"2022-09-19T18:27:03.796425Z","shell.execute_reply.started":"2022-09-19T18:27:03.787696Z","shell.execute_reply":"2022-09-19T18:27:03.79523Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"dictionary2 = [' '.join(tup) for tup in bigrams_list]\nprint (dictionary2)","metadata":{"execution":{"iopub.status.busy":"2022-09-19T18:27:13.892685Z","iopub.execute_input":"2022-09-19T18:27:13.893078Z","iopub.status.idle":"2022-09-19T18:27:13.902255Z","shell.execute_reply.started":"2022-09-19T18:27:13.893047Z","shell.execute_reply":"2022-09-19T18:27:13.900678Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Using count vectoriser to view the frequency of bigrams\nvectorizer = CountVectorizer(ngram_range=(2, 2))\nbag_of_words = vectorizer.fit_transform(dictionary2)\nvectorizer.vocabulary_","metadata":{"execution":{"iopub.status.busy":"2022-09-19T18:27:20.512021Z","iopub.execute_input":"2022-09-19T18:27:20.512374Z","iopub.status.idle":"2022-09-19T18:27:20.572452Z","shell.execute_reply.started":"2022-09-19T18:27:20.512345Z","shell.execute_reply":"2022-09-19T18:27:20.571326Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"sum_words = bag_of_words.sum(axis=0)\nwords_freq = [(word, sum_words[0, idx]) for word, idx in vectorizer.vocabulary_.items()]\nwords_freq = sorted(words_freq, key = lambda x: x[1], reverse=True)\nprint(words_freq[:100])","metadata":{"execution":{"iopub.status.busy":"2022-09-19T18:27:34.669082Z","iopub.execute_input":"2022-09-19T18:27:34.66944Z","iopub.status.idle":"2022-09-19T18:27:34.683911Z","shell.execute_reply.started":"2022-09-19T18:27:34.669412Z","shell.execute_reply":"2022-09-19T18:27:34.682696Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generating wordcloud\nwords_dict = dict(words_freq)\nWC_height = 1000\nWC_width = 1500\nWC_max_words = 100\nwordCloud = WordCloud(max_words=WC_max_words, height=WC_height, width=WC_width, stopwords=new_stopwords)\n\nwordCloud.generate_from_frequencies(words_dict)\nplt.figure(4)\nplt.title('Most frequently occurring bigrams connected by same colour and font size')\nplt.imshow(wordCloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-09-19T18:27:38.301808Z","iopub.execute_input":"2022-09-19T18:27:38.30223Z","iopub.status.idle":"2022-09-19T18:27:40.64574Z","shell.execute_reply.started":"2022-09-19T18:27:38.302197Z","shell.execute_reply":"2022-09-19T18:27:40.644542Z"},"trusted":true},"execution_count":null,"outputs":[]}]}